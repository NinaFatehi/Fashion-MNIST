{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:\\\\Users\\\\Hana\\\\Downloads\\\\fashion-mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        9\n",
       "2        6\n",
       "3        0\n",
       "4        3\n",
       "        ..\n",
       "59995    9\n",
       "59996    1\n",
       "59997    8\n",
       "59998    8\n",
       "59999    7\n",
       "Name: label, Length: 60000, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 359.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), pandas.core.series.Series)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_data['label']\n",
    "y_train.shape, type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"C:\\\\Users\\\\Hana\\\\Downloads\\\\fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_data.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>182</td>\n",
       "      <td>199</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>119</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0          0       0       0       0       0       0       0       9       8   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          0       0       0       0       0       0      14      53      99   \n",
       "3          0       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9995       0       0       0       0       0       0       0       0       0   \n",
       "9996       0       0       0       0       0       0       0       0       0   \n",
       "9997       0       0       0       0       0       0       0       0       0   \n",
       "9998       0       1       3       0       0       0       0       0       0   \n",
       "9999       0       0       0       0       0       0       0     140     119   \n",
       "\n",
       "      pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...       103        87        56         0         0   \n",
       "1           0  ...        34         0         0         0         0   \n",
       "2          17  ...         0         0         0         0        63   \n",
       "3         161  ...       137       126       140         0       133   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "9995       37  ...        32        23        14        20         0   \n",
       "9996        0  ...         0         0         0         2        52   \n",
       "9997        0  ...       175       172       172       182       199   \n",
       "9998        0  ...         0         0         0         0         0   \n",
       "9999      103  ...       111        95        75        44         1   \n",
       "\n",
       "      pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0            0         0         0         0         0  \n",
       "1            0         0         0         0         0  \n",
       "2           53        31         0         0         0  \n",
       "3          224       222        56         0         0  \n",
       "4            0         0         0         0         0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "9995         0         1         0         0         0  \n",
       "9996        23        28         0         0         0  \n",
       "9997       222        42         0         1         0  \n",
       "9998         1         0         0         0         0  \n",
       "9999         0         0         0         0         0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.  16.  36. 226. 164. 227. 230. 224. 255. 254. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 222. 220. 239. 255. 180.\n",
      " 189. 105. 167. 219. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 194. 206. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 211. 189. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 212. 188. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 237. 232. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 254. 227. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 236. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 254. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 249. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 245. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 253. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 250. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 244. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 252. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 246. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 245. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 233. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 248. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 233. 233. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 233. 245. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 239. 227. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 248. 227. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 246.  81. 239. 230. 252. 250. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      " 170.]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.88888889, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.88888889, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.88888889, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.77777778, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.00487805,\n",
       "        0.        ],\n",
       "       [0.        , 0.02222222, 0.01376147, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 4 , explained variance = 0.57412239385557\n",
      "Number of components = 10 , explained variance = 0.718235445032071\n",
      "Number of components = 15 , explained variance = 0.7581398669014439\n",
      "Number of components = 20 , explained variance = 0.7844490191872481\n",
      "Number of components = 25 , explained variance = 0.8041249044243017\n",
      "Number of components = 30 , explained variance = 0.8202364269257195\n",
      "Number of components = 35 , explained variance = 0.8333627122704694\n",
      "Number of components = 50 , explained variance = 0.8623263133670774\n",
      "Number of components = 60 , explained variance = 0.8761304868972698\n",
      "Number of components = 70 , explained variance = 0.887517034153319\n",
      "Number of components = 80 , explained variance = 0.8969593689659024\n",
      "Number of components = 90 , explained variance = 0.9049839228911851\n",
      "Number of components = 100 , explained variance = 0.9120382767621834\n",
      "Number of components = 150 , explained variance = 0.9372195746219556\n",
      "Number of components = 200 , explained variance = 0.9533632872712455\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_comp = [4,10,15,20,25,30,35,50,60,70,80,90,100,150,200] # list containing different values of components\n",
    "explained = [] # explained variance ratio for each component of Truncated SVD\n",
    "for x in n_comp:\n",
    "    svd = TruncatedSVD(n_components=x)\n",
    "    svd.fit(x_train)\n",
    "    explained.append(svd.explained_variance_ratio_.sum())\n",
    "    print(\"Number of components = {} , explained variance = {}\".format(x,svd.explained_variance_ratio_.sum()))\n",
    "plt.plot(n_comp, explained)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.title(\"Plot of Number of components v/s explained variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the number of component equals 90, because after this value the sum of variances are more than 0.9. this is what that we can interpret from the figure as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 90 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd1 = TruncatedSVD(n_components=90, n_iter=7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=90, n_iter=7, random_state=42)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd1.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9051237979229327\n"
     ]
    }
   ],
   "source": [
    "print(svd1.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n",
      "[0.24838832 0.19300838 0.0790306  0.05369509 0.03886173 0.03475562\n",
      " 0.02348599 0.02005794 0.01383273 0.01311912 0.01012818 0.00925858\n",
      " 0.00766671 0.00661234 0.0062446  0.00601077 0.00581432 0.0053345\n",
      " 0.0045999  0.00455758 0.00433538 0.0040769  0.00386047 0.00378609\n",
      " 0.00364068 0.00351219 0.00336396 0.00318722 0.00312667 0.00295705\n",
      " 0.00276345 0.00265469 0.00263194 0.00258002 0.00247568 0.00238424\n",
      " 0.0023075  0.00224454 0.00219134 0.00210362 0.00200854 0.00197996\n",
      " 0.00194218 0.0018423  0.00176818 0.00172439 0.00168038 0.00165309\n",
      " 0.00162388 0.00157205 0.0015448  0.00150869 0.00147742 0.00143907\n",
      " 0.00138494 0.00137491 0.00132051 0.0012924  0.00127142 0.00126473\n",
      " 0.00123108 0.00121001 0.00118078 0.00116718 0.0011538  0.00112072\n",
      " 0.0011151  0.00109622 0.00106008 0.00104902 0.00104438 0.0010226\n",
      " 0.0009731  0.00095496 0.00093681 0.0009356  0.00093124 0.00090206\n",
      " 0.00089056 0.00086828 0.0008442  0.00083898 0.00082053 0.00081324\n",
      " 0.00080944 0.00079754 0.00077456 0.00076349 0.00075183 0.00074598]\n"
     ]
    }
   ],
   "source": [
    "print(svd1.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before applying SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  naive_bayes\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       5       0   \n",
       "3           0       0       0       1       2       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59995       0       0       0       0       0       0       0       0       0   \n",
       "59996       0       0       0       0       0       0       0       0       0   \n",
       "59997       0       0       0       0       0       0       0       0       0   \n",
       "59998       0       0       0       0       0       0       0       0       0   \n",
       "59999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0            0  ...         0         0         0         0         0   \n",
       "1            0  ...         0         0         0         0         0   \n",
       "2            0  ...         0         0         0        30        43   \n",
       "3            0  ...         3         0         0         0         0   \n",
       "4            0  ...         0         0         0         0         0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "59995        0  ...         0         0         0         0         0   \n",
       "59996        0  ...        73         0         0         0         0   \n",
       "59997        0  ...       160       162       163       135        94   \n",
       "59998        0  ...         0         0         0         0         0   \n",
       "59999        0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[60000 rows x 784 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we split the train set into train and validation set and test the accuracy with different alpha rates, and then we check the accuracy of validation set, whenever it starts to decrease (the so-called elbow) the hyper parameter is chosen. Then, with this hyper parameter we tune the classifier and test it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_new, x_validation, y_train_new, y_validation = train_test_split(x_train, y_train, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score with alpha = 0.1 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.01 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.001 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.2 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.002 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.3 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.4 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.5 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.7 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.8 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 0.9 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 1 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 2 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 3 -> 66.78333333333333 \n",
      "Naive Bayes Accuracy Score with alpha = 4 -> 66.78333333333333 \n"
     ]
    }
   ],
   "source": [
    "for i in [0.1,0.01,0.001,0.2,0.002,0.3,0.4,0.5,0.7,0.8,0.9,1,2,3,4]:\n",
    "    Naive = naive_bayes.MultinomialNB(alpha=i)\n",
    "    Naive.fit(x_train, y_train)\n",
    "    # predict the labels on test dataset\n",
    "    predictions_NB = Naive.predict(x_validation)\n",
    "    # Use accuracy_score function to get the accuracy\n",
    "    print(\"Naive Bayes Accuracy Score with alpha = {} -> {} \".format(i, accuracy_score(predictions_NB, y_validation)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  66.74\n"
     ]
    }
   ],
   "source": [
    "#fit the training dataset on the NB classifier\n",
    "# alpha = 1\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(x_train, y_train)\n",
    "# predict the labels on test dataset\n",
    "predictions_NB = Naive.predict(x_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After applying SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd2 = TruncatedSVD(n_components=90, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd2.fit(x_train, y_train)\n",
    "x_train_reducted = svd2.transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 90)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_reducted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd2.fit(x_test, y_test)\n",
    "x_test_reducted = svd2.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 90)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_reducted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-282-343b93c94eb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#fit the training dataset on the NB classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mNaive_reducted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mNaive_reducted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_reducted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# predict the labels on test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredictions_NB_reducted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNaive_reducted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_reducted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "#fit the training dataset on the NB classifier\n",
    "Naive_reducted = naive_bayes.MultinomialNB()\n",
    "Naive_reducted.fit(x_train_reducted, y_train)\n",
    "# predict the labels on test dataset\n",
    "predictions_NB_reducted = Naive_reducted.predict(x_test_reducted)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes with SVD Accuracy Score -> \",accuracy_score(predictions_NB_reducted, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is based on applying Bayes' theorem with strong independence assumptions between the features and this error might be because of this fact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guassian Niave Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before applying SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  59.14\n"
     ]
    }
   ],
   "source": [
    "NaiveG = naive_bayes.GaussianNB()\n",
    "NaiveG.fit(x_train, y_train)\n",
    "# predict the labels on test dataset\n",
    "predictions_GNB = NaiveG.predict(x_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_GNB, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After applying SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  72.05\n"
     ]
    }
   ],
   "source": [
    "NaiveG_reducted = naive_bayes.GaussianNB()\n",
    "NaiveG_reducted.fit(x_train_reducted, y_train)\n",
    "# predict the labels on test dataset\n",
    "predictions_GNB_reducted = NaiveG_reducted.predict(x_test_reducted)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_GNB_reducted, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results of accuracy, we can see that applying SVD increases the performance of Naive Bayes classifier in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinominal Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before applying the SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score with penalty = l1 -> 86.00833333333333 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score with penalty = l2 -> 86.00833333333333 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score with penalty = elasticnet -> 86.00833333333333 \n",
      "Logistic Regression Accuracy Score with penalty = none -> 86.00833333333333 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## get the results for different Penalty, in these step, we use train and validation set, and then when we find the optimal hyper parameters we test the accuracy on the test set.\n",
    "for i in ['l1', 'l2', 'elasticnet', 'none']:\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    predictions_lr = lr.predict(x_validation)\n",
    "    print(\"Logistic Regression Accuracy Score with penalty = {} -> {} \".format(i,accuracy_score(predictions_lr, y_validation)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above results it seems that altering the penalty makes no changes in the accuracy, so we just use the default one for our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score ->  85.44\n"
     ]
    }
   ],
   "source": [
    "## train and test data\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "predictions_lr = lr.predict(x_test)\n",
    "print(\"Logistic Regression Accuracy Score -> \",accuracy_score(predictions_lr, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After applying the SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score ->  70.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_reducted = LogisticRegression()\n",
    "lr_reducted.fit(x_train_reducted, y_train)\n",
    "predictions_lr_reducted = lr_reducted.predict(x_test_reducted)\n",
    "print(\"Logistic Regression Accuracy Score -> \",accuracy_score(predictions_lr_reducted, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before applying SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test split on the original dataset\n",
    "X_train_new, x_validation, y_train_new, y_validation = train_test_split(x_train, y_train, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (48000,))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.shape, y_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 784), (12000,))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validation.shape, y_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think my laptop couldn't handle the KNN on original dataset and it took alot of time, so I just interrupted the kernal for the following for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score for k 3 -> 85.61666666666666 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-275-f30c21f718ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpredictions_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"KNN Accuracy Score for k {} -> {} \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    660\u001b[0m                 \u001b[0mdelayed_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_tree_query_parallel_helper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m                 \u001b[0mparallel_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"prefer\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"threads\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             chunked_results = Parallel(n_jobs, **parallel_kwargs)(\n\u001b[0m\u001b[0;32m    663\u001b[0m                 delayed_query(\n\u001b[0;32m    664\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in list(range(3,20,2)):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_new, y_train_new)\n",
    "    predictions_knn = knn.predict(x_validation)\n",
    "    print(\"KNN Accuracy Score for k {} -> {} \".format(k, accuracy_score(predictions_knn, y_validation)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_new, y_train_new)\n",
    "predictions_knn = knn.predict(x_test)\n",
    "print(\"KNN Accuracy Score on test set for -> {} \".format(k, accuracy_score(predictions_knn, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After applying SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reducted, X_validation_reducted, y_train_reducted, y_validation_reducted = train_test_split(x_train_reducted, y_train,\n",
    "                                                                                       test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 90)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reducted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 90)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation_reducted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000,)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_reducted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation_reducted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal k = [3, 5, 7, 9, 11, 13, 15, 17, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 7, 9, 11, 13, 15, 17, 19]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(3,20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score for k 3 -> 85.98333333333333 \n",
      "KNN Accuracy Score for k 5 -> 86.13333333333333 \n",
      "KNN Accuracy Score for k 7 -> 86.04166666666667 \n",
      "KNN Accuracy Score for k 9 -> 85.83333333333333 \n",
      "KNN Accuracy Score for k 11 -> 85.8 \n",
      "KNN Accuracy Score for k 13 -> 85.725 \n",
      "KNN Accuracy Score for k 15 -> 85.64166666666667 \n",
      "KNN Accuracy Score for k 17 -> 85.48333333333333 \n",
      "KNN Accuracy Score for k 19 -> 85.31666666666666 \n"
     ]
    }
   ],
   "source": [
    "for k in list(range(3,20,2)):\n",
    "    KNN_reducted = KNeighborsClassifier(n_neighbors=k)\n",
    "    KNN_reducted.fit(X_train_reducted, y_train_reducted)\n",
    "    predictions_KNN_reducted = KNN_reducted.predict(X_validation_reducted)\n",
    "    print(\"KNN Accuracy Score for k {} -> {} \".format(k, accuracy_score(predictions_KNN_reducted, y_validation_reducted)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results we can interpret that k=5 is our optimal k since after this k the validation set accuracy starts to reduce. Therefore, our final accuracy on the test data is computated with k=5 as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score for -> 77.27000000000001 \n"
     ]
    }
   ],
   "source": [
    "KNN_reducted = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN_reducted.fit(X_train_reducted, y_train_reducted)\n",
    "predictions_KNN_reducted = KNN_reducted.predict(x_test_reducted)\n",
    "print(\"KNN Accuracy Score for -> {} \".format(accuracy_score(predictions_KNN_reducted, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results we can see that performance of KNN with SVD on the test set is better than other ML algorithms. its accuracy is 77.27, the Naive Bayes accuracy is about 72 and the Logistic Regression is 70.59."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
